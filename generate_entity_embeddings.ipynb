{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import torch\n",
    "from blink.biencoder.biencoder import BiEncoderRanker, load_biencoder, BertEncoder\n",
    "from pytorch_transformers.modeling_bert import (\n",
    "    BertPreTrainedModel,\n",
    "    BertConfig,\n",
    "    BertModel,\n",
    ")\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "\n",
    "\n",
    "biencoder_config = \"models/biencoder_wiki_large.json\"\n",
    "biencoder_model = \"models/biencoder_wiki_large.bin\"\n",
    "with open(biencoder_config) as json_file:\n",
    "    biencoder_params = json.load(json_file)\n",
    "    biencoder_params[\"path_to_model\"] = biencoder_model\n",
    "\n",
    "# candidate encoder\n",
    "# biencoder = load_biencoder(biencoder_params)\n",
    "cand_bert = BertModel.from_pretrained(biencoder_params['bert_model'])\n",
    "cand_encoder = BertEncoder(\n",
    "    cand_bert,\n",
    "    biencoder_params[\"out_dim\"],\n",
    "    layer_pulled=biencoder_params[\"pull_from_layer\"],\n",
    "    add_linear=biencoder_params[\"add_linear\"],\n",
    ")\n",
    "state_dict = torch.load(biencoder_params[\"path_to_model\"])\n",
    "cand_encoder.load_state_dict({k[13:]: v for k, v in state_dict.items() if \"cand_encoder\" in k})\n",
    "cand_encoder.training = False\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    biencoder_params[\"bert_model\"], do_lower_case=biencoder_params[\"lowercase\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephant\n",
      "Mouse\n",
      "Laptop\n",
      "Burger\n",
      "CUP\n",
      "Cup\n"
     ]
    }
   ],
   "source": [
    "from blink.biencoder.data_process import get_candidate_representation\n",
    "from blink.biencoder.biencoder import to_bert_input\n",
    "\n",
    "with open(\"title2desc.json\", \"r\") as f:\n",
    "    title2desc = json.load( f)\n",
    "\n",
    "title2vecs = {}\n",
    "for title, desc in title2desc.items():\n",
    "    print(title)\n",
    "    tokens = get_candidate_representation(desc, tokenizer, biencoder_params[\"max_cand_length\"], title)\n",
    "    \n",
    "    token_ids = torch.tensor(tokens['ids'], dtype=torch.long).unsqueeze(0)\n",
    "    token_idx_cands, segment_idx_cands, mask_cands = to_bert_input(token_ids, 0) \n",
    "    embedding_cands = cand_encoder(\n",
    "        token_idx_cands, segment_idx_cands, mask_cands\n",
    "    )\n",
    "    \n",
    "    title2vecs[title] = embedding_cands.to(\"cpu\").squeeze()\n",
    "\n",
    "# cos = torch.nn.CosineSimilarity(dim=0)\n",
    "# \n",
    "# e1 = title2vecs['Laptop']\n",
    "# e2 = title2vecs['Mouse']\n",
    "# e3 = title2vecs['Cup']\n",
    "# e4 = title2vecs['Elephant']\n",
    "# e5 = title2vecs['Burger']\n",
    "# \n",
    "# print(cos(torch.tensor(e1), torch.tensor(e2)).item())\n",
    "# print(cos(torch.tensor(e1), torch.tensor(e3)).item())\n",
    "# print(cos(torch.tensor(e1), torch.tensor(e4)).item())\n",
    "# print(cos(torch.tensor(e1), torch.tensor(e5)).item())\n",
    "\n",
    "# 0.8001438975334167\n",
    "# 0.7863001823425293\n",
    "# 0.7561507821083069\n",
    "# 0.7998831868171692\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('blink37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6592d5a678606710412ea69b65231d71e685a38a91121ba851e413f0358400f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
